---
layout: default
title: Home
---
<div class="page">
  
  <header>
    <h1 class="landing-title">Violin Diffusion</h1>
    <div class="social-icons text-center">
      <a href="https://arxiv.org/abs/your-paper-link" target="_blank">
        <i class="fa fa-file-pdf-o fa-2x" aria-hidden="true" title="View Paper on arXiv"></i>
      </a>
      <a href="https://github.com/your-repo-link" target="_blank">
        <i class="fa fa-github fa-2x" aria-hidden="true" title="View Code on GitHub"></i>
      </a>
    </div>

  </header>
  
  ## Abstract
  <section class="abstract-section">
    <h2>Abstract</h2>
    <p class="message">
      Synthesizing expressive violin performances is a complex task due to the need for intricate pitch variations, such as vibrato and glissando, which are often missing in standard MIDI data. To address this, we introduce a two-stage neural synthesis framework. The first stage, \textbf{DiffBend}, estimates the missing pitch bend information, while the second stage, \textbf{DiffSynth}, generates high-fidelity audio incorporating these expressive details. Our method is evaluated using Fréchet Audio Distance (FAD) and vibrato-specific metrics, demonstrating superior performance in both audio quality and expressiveness compared to existing methods. This highlights the critical role of accurate pitch bend modeling in improving the realism of synthesized violin performances.    
    </p>
  </section>

<!--   
  <div class="text-center">
    <p>
      <i class="fa fa-code-fork fa-3x"></i>
    </p>

    <p>
      Welcome to the Violin Diffusion project! This research focuses on synthesizing expressive violin performances through advanced neural synthesis techniques.
    </p>
    
    <h2>Abstract</h2>
    <p>
      Synthesizing expressive violin performances is a complex task due to the need for intricate pitch variations, such as vibrato and glissando, which are often missing in standard MIDI data. To address this, we introduce a two-stage neural synthesis framework. The first stage, <strong>DiffBend</strong>, estimates the missing pitch bend information, while the second stage, <strong>DiffSynth</strong>, generates high-fidelity audio incorporating these expressive details. Our method is evaluated using Fréchet Audio Distance (FAD) and vibrato-specific metrics, demonstrating superior performance in both audio quality and expressiveness compared to existing methods.
    </p>

    <p>
      This is your landing page. It is the first page your users will see when 
      they visit your website. Perhaps write a little bit about you or your 
      website here.
    </p>

    <p>
      Feel free to dive right in and make your changes to the code!<br />
      Or check out Celeste on <a href="https://github.com/nicoelayda/celeste">GitHub</a> 
      to learn more.
    </p>
  </div> -->
  
</div>
